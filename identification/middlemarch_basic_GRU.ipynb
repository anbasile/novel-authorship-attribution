{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization - chars to ints\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Sample predictions from a probability array\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-6) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate(model, diversity=0.5, text=\"\"):\n",
    "    \"\"\"Generate text from a model\"\"\"\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(5000):\n",
    "        x = np.zeros((1, maxlen), dtype=np.int)\n",
    "        for t, char in enumerate(sentence):\n",
    "            try:\n",
    "                x[0, t] = char_indices[char]\n",
    "            except:\n",
    "                print(sentence)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    return\n",
    "\n",
    "def vectorize(text):\n",
    "    \"\"\"Convert text into character sequences\"\"\"\n",
    "    step = 3\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    X = np.zeros((len(sentences), maxlen), dtype=np.int)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_indices[char]\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "def clean_text(text, charset):\n",
    "    text = \" \".join(text.split())  # all white space is one space\n",
    "    text = \"\".join([x for x in text if x in charset])  # remove characters that we don't care about\n",
    "    return text\n",
    "\n",
    "def get_model(modelfile, freeze=False):\n",
    "    model = load_model(modelfile)\n",
    "    if freeze:\n",
    "        for layer in model.layers[:6]:\n",
    "            layer.trainable = False\n",
    "    return model\n",
    "\n",
    "chars = \" \" + string.ascii_letters + string.punctuation  # sorted to keep indices consistent\n",
    "charset = set(chars)  # for lookup\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "maxlen = 100  # must match length which generated model - the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, BatchNormalization, GRU, Dense\n",
    "\n",
    "def get_gru_model(use_embeddings=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(charset), output_dim=300))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GRU(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(85, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"middlemarch.txt\") as f:\n",
    "    middlemarch = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 532465 samples, validate on 59163 samples\n",
      "Epoch 1/10\n",
      "532465/532465 [==============================] - 632s - loss: 1.8219 - val_loss: 1.4924\n",
      "Epoch 2/10\n",
      "532465/532465 [==============================] - 583s - loss: 1.5631 - val_loss: 1.3974\n",
      "Epoch 3/10\n",
      "532465/532465 [==============================] - 585s - loss: 1.4941 - val_loss: 1.3656\n",
      "Epoch 4/10\n",
      "532465/532465 [==============================] - 586s - loss: 1.4551 - val_loss: 1.3468\n",
      "Epoch 5/10\n",
      "532465/532465 [==============================] - 586s - loss: 1.4300 - val_loss: 1.3282\n",
      "Epoch 6/10\n",
      "532465/532465 [==============================] - 589s - loss: 1.4129 - val_loss: 1.3214\n",
      "Epoch 7/10\n",
      "532465/532465 [==============================] - 591s - loss: 1.4012 - val_loss: 1.3156\n",
      "Epoch 8/10\n",
      "532465/532465 [==============================] - 587s - loss: 1.3914 - val_loss: 1.3098\n",
      "Epoch 9/10\n",
      "532465/532465 [==============================] - 589s - loss: 1.3832 - val_loss: 1.3073\n",
      "Epoch 10/10\n",
      "532465/532465 [==============================] - 585s - loss: 1.3794 - val_loss: 1.3061\n",
      "CPU times: user 2h 20min 50s, sys: 13min, total: 2h 33min 51s\n",
      "Wall time: 1h 38min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_model = get_gru_model()\n",
    "X, y = vectorize(clean_text(middlemarch, charset))\n",
    "test_model.fit(X, y, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"t girl to her? Her flame quickly burned up that light fuel; and, fed from within, soared after some \"\n",
      "t girl to her? Her flame quickly burned up that light fuel; and, fed from within, soared after some one of the elder which had a husband and he was a coming to the schual and seemed to take him to apt to the light of some practice on the world seem a wish to Dorothea said that it was only think of the expectation some money with the bearen and father. Then that you was promision of here and was less and shaking a little which she is not stimist that the too world that it was not such a subject of any will and who was seemed to have long in his best of this manner had been a more who would be anything for was not such as should be a be much enduced in the new states of seemed to the dead of professionable who was sented that many seems in his own man whom he said to the more chome to be interprite barnose of the story to a family was a double with a good sense of the sanching her common to be was the sense of mind that he was only that most and words by in Mind which are a very other fellow and political money which was in the words expected by the more to me to be a life, the thing that he was a sudden of man which really senming the studies of the suspecation of something something of many securessed to his hands on his decided with his mind when he had not so felt again of many of the strange to his head on the world with the stronger of with the horse were on the sense of painter with the exclaim of many sartives and the hand of the constance to any consequence of whom he was not a sister seem and thought her many seen home, and because he was of many simply of his conditions of her husband was the dark before her husband, who was still so much to winded it in the suches which was some opinion of say that it was stimling with a bound who was stringing in the winder than her with Fred was so much suspections. He be a little to begin it was the shork to her to any life had with the with a more that he seen out of the sister in the of the world was so, she was land and before the fine passed should be a first common and made the sensing to her husband had a comes of possible of command and under the branked and speaking of his best man in the subject of his simply an expected of proving his hand of the was to be would see all of my opinions was a coming to be a man, and indeed, and said, \"I shall be a stead of seemed a law and in the family distance with the father was stimous to the truth her husband, who only samething in his pertain which short is preasured on her husband's new prospections, and was more except the best in his exclesiarity of westing him in the lawness of her own with the more than in the best lay than the Garth seven of his belief in the struggling his some wish to have all the studion was stringed to be she could not be recovered the possible to shake his man which was gosent enough for her that she was surprised to said to her husband that he was sticking with a sort of found as when I shall be fails against his mother and with a sense of sense of a back of the suspossing to the property in the considered that what would be something of the words this with the tender of the completies with a such man and think of that the tone for the expected of this than that a be arasted the rest of his hand of her husband, and with a strong wished by the delight of my uncle. I could be the more in the words of the business with the storse had the other possible of mind was to be was with his simp, and that Mrs. Hack. \"I am supposing to his had been only promised to make the than that she providence to see him in the uncle in the house of his new place to the way and with the some of the strange in the moment of his face and still into the will as the subject, and with consideration of his decided the duries. He seemed to be should be in the study to be a stuch. The never supposed that he was something in a discontention of the money of only beared any position in the sensition and made the while that he should be for the time had not in the opened any sayed her for the same family and many ladies on the comen of some good expectation which had an expectation of the professionable at the surprise that it was a while what he had only more than the sting with my protetted with the stolt she was the light of his own words in which she was a subject of seeming in a provention which was not make the basket him and see in might have been something that he was so many place to have if there was like a little of provincence of life in the way of still in the suspeciation as professions of this so into the personal things. He would not you can be a genting him with so many some money who ardent had been blonged with the subject of being a come and the reason of things that she was still an and she was looking to be a funder to the more than the profoully on his name secured to say that her husband's the Greate than the about the It wish to see that her husband was not suppose the more interanted and had that the manner of me and then that Mr. Casaubon could be the soul subserving the conscience of things "
     ]
    }
   ],
   "source": [
    "generate(test_model, text=clean_text(middlemarch[:1000], charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model.save(\"middlemarch_basic_gru.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
