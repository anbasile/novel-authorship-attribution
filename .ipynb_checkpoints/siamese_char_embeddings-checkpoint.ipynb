{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import textacy\n",
    "from spacy.en import English\n",
    "\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TextPair:\n",
    "    def __init__(self, author, known, unknown, max_length=1200):\n",
    "        self.author = author\n",
    "        self.known = known\n",
    "        self.unknown = unknown\n",
    "        self.max_length = max_length\n",
    "\n",
    "def get_string(filename):\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        s = f.read()\n",
    "    return s\n",
    "\n",
    "def get_texts(directory):\n",
    "    authors = [x for x in os.listdir(directory) if x.startswith(\"EN\")]\n",
    "    tps = []\n",
    "    for author in authors:\n",
    "        known = os.path.join(directory, author, \"known01.txt\")\n",
    "        unknown = os.path.join(directory, author, \"unknown.txt\")\n",
    "        tps.append(TextPair(author, get_string(known), get_string(unknown)))\n",
    "    return tps\n",
    "\n",
    "def get_data(directory):\n",
    "    \n",
    "    # read all texts into known, unknown pairs\n",
    "    tps = get_texts(directory)\n",
    "    \n",
    "    # get labels\n",
    "    truthfile = os.path.join(directory, \"truth.txt\")\n",
    "    with open(truthfile) as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "    y = [1 if line.split()[1] == \"Y\" else 0 for line in lines]\n",
    "    y = np.array(y)\n",
    "    return tps, y\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # create pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pan15train = \"/data/pan15-authorship-verification-training-dataset-english-2015-04-19/\"\n",
    "pan15test = \"/data/pan15-authorship-verification-test-dataset2-english-2015-04-19/\"\n",
    "pan14train = \"/data/pan14-author-verification-training-corpus-english-essays-2014-04-22/\"\n",
    "pan14test = \"/data/pan14-author-verification-test-corpus2-english-essays-2014-04-22/\"\n",
    "pan14train = \"/data/pan14-author-verification-training-corpus-english-novels-2014-04-22/\"\n",
    "pan14test = \"/data/pan14-author-verification-test-corpus2-english-novels-2014-04-22/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(pan15train)\n",
    "X_test, y_test = get_data(pan15test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"glove.840B.300d-char.txt\") as f:\n",
    "    nlp.vocab.load_vectors(f)\n",
    "    \n",
    "nlp_word = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_distances(tps):\n",
    "    for i in range(len(tps)):\n",
    "        tps[i].known = nlp(tps[i].known)\n",
    "        tps[i].unknown = nlp(tps[i].unknown)\n",
    "    for i in range(len(tps)):\n",
    "        w2v = textacy.similarity.word2vec(tps[i].known, tps[i].unknown)\n",
    "        wm = textacy.similarity.word_movers(tps[i].known, tps[i].unknown)\n",
    "        jc = textacy.similarity.jaccard(str(tps[i].known), str(tps[i].unknown))\n",
    "        hm = textacy.similarity.hamming(str(tps[i].known), str(tps[i].unknown))\n",
    "        jw = textacy.similarity.jaro_winkler(str(tps[i].known), str(tps[i].unknown))\n",
    "        le = textacy.similarity.levenshtein(str(tps[i].known), str(tps[i].unknown))\n",
    "        ts = textacy.similarity.token_sort_ratio(str(tps[i].known), str(tps[i].unknown))\n",
    "        tps[i].distances = [w2v, wm, jc, hm, jw, le, ts]\n",
    "    return tps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text(str_text):\n",
    "    return np.hstack([nlp(str_text, entity=False, tag=False, parse=False).vector, \n",
    "                      nlp_word(str_text, entity=False, tag=False, parse=False).vector])\n",
    "\n",
    "X_train_known = [vectorize_text(x.known) for x in X_train]\n",
    "X_train_unknown = [vectorize_text(x.unknown) for x in X_train]\n",
    "X_test_known = [vectorize_text(x.known) for x in X_test]\n",
    "X_test_unknown = [vectorize_text(x.unknown) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def _vectorize(str_text):\n",
    "    alphabet = string.ascii_lowercase + \"!?:;,.'- \"\n",
    "    processed = nlp(str_text, entity=False, tag=True, parse=True)\n",
    "    stats = textacy.text_stats.TextStats(processed).basic_counts\n",
    "    s_keys = ['n_long_words', 'n_monosyllable_words', 'n_polysyllable_words', 'n_sents', \n",
    "              'n_syllables', 'n_unique_words', 'n_words']\n",
    "    tag_keys = ['ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SPACE', 'SYM', 'VERB', 'X']\n",
    "    tag_keys_set = set(tag_keys)\n",
    "    \n",
    "    ratio_stats = [(key, stats[key] / len(str_text)) for key in s_keys]\n",
    "    \n",
    "    lower_text_ratios = Counter(''.join(filter(lambda x: x in alphabet, str_text.lower() + alphabet)))\n",
    "    for key in lower_text_ratios:\n",
    "        lower_text_ratios[key] /= len(str_text)\n",
    "    \n",
    "    lower_text_ratios = [(key, lower_text_ratios[key]) for key in sorted(list(lower_text_ratios.keys()))]\n",
    "\n",
    "    new_tags = set([word.pos_ for word in processed if word.pos_ not in tag_keys_set])\n",
    "    if len(new_tags) > 0:\n",
    "        print(new_tags)\n",
    "    tags = [word.pos_ for word in processed if word.pos_ in tag_keys_set] + tag_keys\n",
    "    tag_counter_ratios = Counter(tags)\n",
    "    for key in tag_counter_ratios:\n",
    "        tag_counter_ratios[key] /= len(processed)\n",
    "    \n",
    "    tag_counter_ratios = [(key, tag_counter_ratios[key]) for key in sorted(list(tag_counter_ratios.keys()))]\n",
    "    \n",
    "    return ratio_stats + lower_text_ratios + tag_counter_ratios\n",
    "        \n",
    "def vectorize(str_text):\n",
    "    vecs = _vectorize(str_text)\n",
    "    return np.array([x[1] for x in vecs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_known = [vectorize(x.known) for x in X_train]\n",
    "X_train_unknown = [vectorize(x.unknown) for x in X_train]\n",
    "X_test_known = [vectorize(x.known) for x in X_test]\n",
    "X_test_unknown = [vectorize(x.unknown) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58,)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_known[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in test[0]]) - set([x[0] for x in test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_known = [0] * 7\n",
    "mean_unknown = [0] * 7\n",
    "print(mean_known)\n",
    "for i, p in enumerate(X_train):\n",
    "    for j, dm in enumerate(p.distances):\n",
    "        if y_train[i] == 1:\n",
    "            mean_known[j] += dm\n",
    "        else:\n",
    "            mean_unknown[j] += dm\n",
    "            \n",
    "    \n",
    "print(mean_known)\n",
    "print(mean_unknown)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_pairs = [tp.distances for i, tp in enumerate(X_train)]\n",
    "te_pairs = [tp.distances for i, tp in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "Xs = [X_train_known[i] - X_train_unknown[i] for i in range(len(X_train_known))]\n",
    "print(mean(cross_val_score(DecisionTreeClassifier(), Xs, tr_y, cv=5)))\n",
    "# DecisionTreeClassifier().fit(tr_pairs, y_train)\n",
    "# preds = clf.predict(te_pairs)\n",
    "# accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_known_X = [x.known.vector for x in X_train]\n",
    "train_unknown_X = [x.unknown.vector for x in X_train]\n",
    "test_known_X = [x.known.vector for x in X_test]\n",
    "test_unknown_X = [x.unknown.vector for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(knownX, unknownX):\n",
    "    pairs = []\n",
    "    for i in range(len(knownX)):\n",
    "        pairs += [[knownX[i], unknownX[i]]]\n",
    "    pairs = np.array(pairs)\n",
    "    print(pairs.shape)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 66)\n",
      "(500, 2, 66)\n"
     ]
    }
   ],
   "source": [
    "tr_pairs = create_pairs(knownzs, unknownzs)\n",
    "te_pairs = create_pairs(X_test_known, X_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_y = y_train\n",
    "te_y = y_test\n",
    "\n",
    "shuff_tr_y = tr_y[:]\n",
    "shuff_te_y = te_y[:]\n",
    "from random import shuffle\n",
    "shuffle(shuff_tr_y)\n",
    "shuffle(shuff_te_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truthfile = os.path.join(pan15train, \"truth.txt\")\n",
    "with open(truthfile) as f:\n",
    "    lines = f.read().strip().split(\"\\n\")\n",
    "y = [1 if line.split()[1] == \"Y\" else 0 for line in lines]\n",
    "tr_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_y = y_test\n",
    "tr_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(64, input_shape=(input_dim,), activation='relu'))\n",
    "    seq.add(Dense(64))\n",
    "    seq.add(Dense(64))\n",
    "    seq.add(Dense(64))\n",
    "\n",
    "    return seq\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return np.mean(np.equal(predictions.ravel() < 0.5, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_pairs, te_pairs = te_pairs, tr_pairs\n",
    "tr_y, te_y = te_y, tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_dim = tr_pairs.shape[-1]\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_dim)\n",
    "\n",
    "input_a = Input(shape=(input_dim,))\n",
    "input_b = Input(shape=(input_dim,))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 350 samples\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - 1s - loss: 11.3399 - val_loss: 6.1100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 0s - loss: 4.7190 - val_loss: 4.3974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 0s - loss: 3.0609 - val_loss: 3.3006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 0s - loss: 2.1789 - val_loss: 2.6267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 0s - loss: 1.5573 - val_loss: 2.0748\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 0s - loss: 1.1477 - val_loss: 1.7036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 0s - loss: 0.8609 - val_loss: 1.3727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 0s - loss: 0.6501 - val_loss: 1.1270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 0s - loss: 0.4989 - val_loss: 0.9473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 0s - loss: 0.3870 - val_loss: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 0s - loss: 0.3247 - val_loss: 0.6945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 0s - loss: 0.2383 - val_loss: 0.6382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 0s - loss: 0.2042 - val_loss: 0.5629\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 0s - loss: 0.1648 - val_loss: 0.5079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 0s - loss: 0.1602 - val_loss: 0.4426\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 0s - loss: 0.1256 - val_loss: 0.4120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 0s - loss: 0.1104 - val_loss: 0.4676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 0s - loss: 0.1050 - val_loss: 0.3226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 0s - loss: 0.0803 - val_loss: 0.3157\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 0s - loss: 0.0848 - val_loss: 0.3237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 0s - loss: 0.0711 - val_loss: 0.2975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 0s - loss: 0.0647 - val_loss: 0.2477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 0s - loss: 0.0490 - val_loss: 0.2589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 0s - loss: 0.0709 - val_loss: 0.2383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 0s - loss: 0.0499 - val_loss: 0.2225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 0s - loss: 0.0541 - val_loss: 0.2384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 0s - loss: 0.0495 - val_loss: 0.2151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 0s - loss: 0.0444 - val_loss: 0.1902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 0s - loss: 0.0333 - val_loss: 0.1949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 0s - loss: 0.0348 - val_loss: 0.1835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169819eb8>"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          validation_split=0.7,\n",
    "          batch_size=20,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 89.60%\n",
      "* Accuracy on test set: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuff_tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(shuff_tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuff_tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# third-party imports\n",
    "import textacy\n",
    "from spacy.en import English\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def _normalize_counter(counter, c):\n",
    "    \"\"\"Divide all the values in a Counter by a constant and remove padding\"\"\"\n",
    "    for key in counter:\n",
    "        counter[key] = (counter[key] - 1) / c\n",
    "    return counter\n",
    "\n",
    "class TextAnalyser:\n",
    "    def __init__(self, nlp=None):\n",
    "        if nlp:\n",
    "            self.nlp = nlp\n",
    "        else:\n",
    "            self.nlp = English()\n",
    "            \n",
    "        # alphabet for letter ratios\n",
    "        self.alphabet = string.ascii_lowercase + \"!?:;,.'- \"\n",
    "        \n",
    "        # keys that we care about from textacy.stats\n",
    "        self.basic_keys = ['n_long_words', 'n_monosyllable_words', 'n_polysyllable_words', 'n_sents', 'n_syllables', 'n_unique_words', 'n_words']\n",
    "        \n",
    "        # keys that we care about for textacy readability stats\n",
    "        self.readability_keys = ['automated_readability_index','coleman_liau_index', 'flesch_kincaid_grade_level',\n",
    "                                 'flesch_readability_ease', 'gulpease_index', 'gunning_fog_index', 'lix',\n",
    "                                 'wiener_sachtextformel']\n",
    "        \n",
    "        # parts of speech that we care about from spacy (pos_ not tag_)\n",
    "        self.pos_keys = ['ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SPACE', 'SYM', 'VERB', 'X']\n",
    "        self.pos_keys_set = set(self.pos_keys)\n",
    "\n",
    "    def get_named_features(self, text):\n",
    "        # TODO: Add bigrams, trigrams?\n",
    "        processed = self.nlp(text, entity=False, tag=True, parse=True)\n",
    "        stats = textacy.text_stats.TextStats(processed)\n",
    "        basic_stats = stats.basic_counts\n",
    "        readability_stats = stats.readability_stats\n",
    "        cleaned_text = ''.join(filter(lambda x: x in self.alphabet, text.lower() + self.alphabet))\n",
    "        \n",
    "        stats_ratios = {key: (basic_stats[key] / len(text)) for key in self.basic_keys}\n",
    "        readability_ratios = {key: (readability_stats[key] / len(text)) for key in self.readability_keys}\n",
    "        stats_ratios.update(readability_ratios)\n",
    "\n",
    "        # get only the characters we care about \n",
    "        # append alphabet so that each character artificially appears once\n",
    "        char_ratios = Counter(cleaned_text)\n",
    "        char_ratios = _normalize_counter(char_ratios, len(text))\n",
    "\n",
    "        # calculate pos ratios\n",
    "        tags = [word.pos_ for word in processed if word.pos_ in self.pos_keys_set] + self.pos_keys\n",
    "        pos_ratios = Counter(tags)\n",
    "        pos_ratios = _normalize_counter(pos_ratios, len(processed)) # normalize by word length\n",
    "\n",
    "        res = stats_ratios\n",
    "        res.update(char_ratios)\n",
    "        res.update(pos_ratios)\n",
    "        return [(key, res[key]) for key in sorted(res)]\n",
    "    \n",
    "    def calculate_mean_and_std(self, extracted_texts):\n",
    "        \"\"\"finds unusual patterns by calculating mean and std deviation for a list of \n",
    "           extracted features and sorting by z-score\"\"\"\n",
    "        means = []\n",
    "        stds = []\n",
    "        sample = extracted_texts[0]  # get one text for feature size and names\n",
    "        num_features = len(sample)\n",
    "        # fi = feature index\n",
    "        for fi in range(num_features):\n",
    "            u = mean([stat[fi][1] for stat in extracted_texts])\n",
    "            o = stdev([stat[fi][1] for stat in extracted_texts])\n",
    "            means.append((sample[fi][0], u))\n",
    "            stds.append((sample[fi][0], o))\n",
    "        return means, stds\n",
    "    \n",
    "    def calculate_z_scores(self, extracted_text, means, stds):\n",
    "        \"\"\"Calculate the zscores for each features of a single text (extractions)\"\"\"\n",
    "        # z = (X - μ) / σ\n",
    "        zscores = []\n",
    "        num_features = len(extracted_text)\n",
    "        for fi in range(num_features):\n",
    "            feature_name = extracted_text[fi][0]\n",
    "            try:\n",
    "                zscore = (extracted_text[fi][1] - means[fi][1]) / stds[fi][1]\n",
    "            except ZeroDivisionError:\n",
    "                zscore = 0\n",
    "            zscores.append((zscore, feature_name))\n",
    "        return zscores\n",
    "        \n",
    "def vectorize(str_text):\n",
    "    vecs = _vectorize(str_text)\n",
    "    return np.array([x[1] for x in vecs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_unusual_features(zscores, nfeatures=5):\n",
    "    zscores = sorted(zscores)\n",
    "    s = \"\"\n",
    "    for j in range(nfeatures):\n",
    "        fname = zscores[j][1]\n",
    "        padding = \" \" * (30 - len(fname))\n",
    "        s += \"{} is low {}(zscore: {})\\n\".format(fname, padding, zscores[j][0])\n",
    "    s += \"    . . .     \\n\"\n",
    "    for j in range(nfeatures):\n",
    "        fname = zscores[-(j + 1)][1]\n",
    "        padding = \" \" * (30 - len(fname))\n",
    "        s += \"{} is high{}(zscore: {})\\n\".format(fname, padding, zscores[-(j + 1)][0])\n",
    "    return s\n",
    "\n",
    "def supports_and_opposes(zscores1, zscores2, sup_threshold=1.5):\n",
    "    supports = []\n",
    "    opposes = []\n",
    "    for i in range(len(zscores1)):\n",
    "        # both are high or low\n",
    "        if (zscores1[i][0] > sup_threshold and zscores2[i][0] > sup_threshold) or (\n",
    "            zscores1[i][0] < -sup_threshold and zscores2[i][0] < -sup_threshold):\n",
    "            supports.append((zscores1[i], zscores2[i]))\n",
    "        # one is high and the other is low\n",
    "        if (zscores1[i][0] > sup_threshold and zscores2[i][0] < -sup_threshold) or (\n",
    "            zscores1[i][0] < -sup_threshold and zscores2[i][0] > sup_threshold):\n",
    "            opposes.append((zscores1[i], zscores2[i]))\n",
    "    return supports, opposes\n",
    "         \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def t(knowns, unknowns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [1 if p else 0 for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n"
     ]
    }
   ],
   "source": [
    "def get(tps):\n",
    "    knownstats = [ta.get_named_features(text) for text in [x.known for x in tps]]\n",
    "    unknownstats = [ta.get_named_features(text) for text in [x.unknown for x in tps]]\n",
    "    means, stds = ta.calculate_mean_and_std(knownstats + unknownstats)\n",
    "    knownzs = [ta.calculate_z_scores(ks, means, stds) for ks in knownstats]\n",
    "    unknownzs = [ta.calculate_z_scores(ks, means, stds) for ks in unknownstats]\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(tps)):\n",
    "        z1 = knownzs[i]\n",
    "        z2 = unknownzs[i]\n",
    "        s, o = supports_and_opposes(z1, z2, sup_threshold=0.2)\n",
    "        preds.append(len(s) > len(o))\n",
    "    return preds\n",
    "\n",
    "preds_train = get(X_train)\n",
    "preds_test = get(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 68, False: 32})\n",
      "Counter({True: 288, False: 212})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(preds_train))\n",
    "print(Counter(preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67       250\n",
      "          1       0.67      0.77      0.71       250\n",
      "\n",
      "avg / total       0.70      0.69      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.58      0.71        50\n",
      "          1       0.69      0.94      0.80        50\n",
      "\n",
      "avg / total       0.80      0.76      0.75       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
