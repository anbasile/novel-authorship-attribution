{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import textacy\n",
    "from spacy.en import English\n",
    "\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TextPair:\n",
    "    def __init__(self, author, known, unknown, max_length=1200):\n",
    "        self.author = author\n",
    "        self.known = known\n",
    "        self.unknown = unknown\n",
    "        self.max_length = max_length\n",
    "\n",
    "def get_string(filename):\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        s = f.read()\n",
    "    return s\n",
    "\n",
    "def get_texts(directory):\n",
    "    authors = [x for x in os.listdir(directory) if x.startswith(\"EN\")]\n",
    "    tps = []\n",
    "    for author in authors:\n",
    "        known = os.path.join(directory, author, \"known01.txt\")\n",
    "        unknown = os.path.join(directory, author, \"unknown.txt\")\n",
    "        tps.append(TextPair(author, get_string(known), get_string(unknown)))\n",
    "    return tps\n",
    "\n",
    "def get_data(directory):\n",
    "    \n",
    "    # read all texts into known, unknown pairs\n",
    "    tps = get_texts(directory)\n",
    "    \n",
    "    # get labels\n",
    "    truthfile = os.path.join(directory, \"truth.txt\")\n",
    "    with open(truthfile) as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "    y = [1 if line.split()[1] == \"Y\" else 0 for line in lines]\n",
    "    y = np.array(y)\n",
    "    return tps, y\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # create pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pan15train = \"/data/pan15-authorship-verification-training-dataset-english-2015-04-19/\"\n",
    "pan15test = \"/data/pan15-authorship-verification-test-dataset2-english-2015-04-19/\"\n",
    "pan14train = \"/data/pan14-author-verification-training-corpus-english-essays-2014-04-22/\"\n",
    "pan14test = \"/data/pan14-author-verification-test-corpus2-english-essays-2014-04-22/\"\n",
    "pan14train = \"/data/pan14-author-verification-training-corpus-english-novels-2014-04-22/\"\n",
    "pan14test = \"/data/pan14-author-verification-test-corpus2-english-novels-2014-04-22/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(pan15train)\n",
    "X_test, y_test = get_data(pan15test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"glove.840B.300d-char.txt\") as f:\n",
    "    nlp.vocab.load_vectors(f)\n",
    "    \n",
    "nlp_word = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_distances(tps):\n",
    "    for i in range(len(tps)):\n",
    "        tps[i].known = nlp(tps[i].known)\n",
    "        tps[i].unknown = nlp(tps[i].unknown)\n",
    "    for i in range(len(tps)):\n",
    "        w2v = textacy.similarity.word2vec(tps[i].known, tps[i].unknown)\n",
    "        wm = textacy.similarity.word_movers(tps[i].known, tps[i].unknown)\n",
    "        jc = textacy.similarity.jaccard(str(tps[i].known), str(tps[i].unknown))\n",
    "        hm = textacy.similarity.hamming(str(tps[i].known), str(tps[i].unknown))\n",
    "        jw = textacy.similarity.jaro_winkler(str(tps[i].known), str(tps[i].unknown))\n",
    "        le = textacy.similarity.levenshtein(str(tps[i].known), str(tps[i].unknown))\n",
    "        ts = textacy.similarity.token_sort_ratio(str(tps[i].known), str(tps[i].unknown))\n",
    "        tps[i].distances = [w2v, wm, jc, hm, jw, le, ts]\n",
    "    return tps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text(str_text):\n",
    "    return np.hstack([nlp(str_text, entity=False, tag=False, parse=False).vector, \n",
    "                      nlp_word(str_text, entity=False, tag=False, parse=False).vector])\n",
    "\n",
    "X_train_known = [vectorize_text(x.known) for x in X_train]\n",
    "X_train_unknown = [vectorize_text(x.unknown) for x in X_train]\n",
    "X_test_known = [vectorize_text(x.known) for x in X_test]\n",
    "X_test_unknown = [vectorize_text(x.unknown) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def _vectorize(str_text):\n",
    "    alphabet = string.ascii_lowercase + \"!?:;,.'- \"\n",
    "    processed = nlp(str_text, entity=False, tag=True, parse=True)\n",
    "    stats = textacy.text_stats.TextStats(processed).basic_counts\n",
    "    s_keys = ['n_long_words', 'n_monosyllable_words', 'n_polysyllable_words', 'n_sents', \n",
    "              'n_syllables', 'n_unique_words', 'n_words']\n",
    "    tag_keys = ['ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SPACE', 'SYM', 'VERB', 'X']\n",
    "    tag_keys_set = set(tag_keys)\n",
    "    \n",
    "    ratio_stats = [(key, stats[key] / len(str_text)) for key in s_keys]\n",
    "    \n",
    "    lower_text_ratios = Counter(''.join(filter(lambda x: x in alphabet, str_text.lower() + alphabet)))\n",
    "    for key in lower_text_ratios:\n",
    "        lower_text_ratios[key] /= len(str_text)\n",
    "    \n",
    "    lower_text_ratios = [(key, lower_text_ratios[key]) for key in sorted(list(lower_text_ratios.keys()))]\n",
    "\n",
    "    new_tags = set([word.pos_ for word in processed if word.pos_ not in tag_keys_set])\n",
    "    if len(new_tags) > 0:\n",
    "        print(new_tags)\n",
    "    tags = [word.pos_ for word in processed if word.pos_ in tag_keys_set] + tag_keys\n",
    "    tag_counter_ratios = Counter(tags)\n",
    "    for key in tag_counter_ratios:\n",
    "        tag_counter_ratios[key] /= len(processed)\n",
    "    \n",
    "    tag_counter_ratios = [(key, tag_counter_ratios[key]) for key in sorted(list(tag_counter_ratios.keys()))]\n",
    "    \n",
    "    return ratio_stats + lower_text_ratios + tag_counter_ratios\n",
    "        \n",
    "def vectorize(str_text):\n",
    "    vecs = _vectorize(str_text)\n",
    "    return np.array([x[1] for x in vecs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_known = [vectorize(x.known) for x in X_train]\n",
    "X_train_unknown = [vectorize(x.unknown) for x in X_train]\n",
    "X_test_known = [vectorize(x.known) for x in X_test]\n",
    "X_test_unknown = [vectorize(x.unknown) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58,)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_known[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in test[0]]) - set([x[0] for x in test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_known = [0] * 7\n",
    "mean_unknown = [0] * 7\n",
    "print(mean_known)\n",
    "for i, p in enumerate(X_train):\n",
    "    for j, dm in enumerate(p.distances):\n",
    "        if y_train[i] == 1:\n",
    "            mean_known[j] += dm\n",
    "        else:\n",
    "            mean_unknown[j] += dm\n",
    "            \n",
    "    \n",
    "print(mean_known)\n",
    "print(mean_unknown)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_pairs = [tp.distances for i, tp in enumerate(X_train)]\n",
    "te_pairs = [tp.distances for i, tp in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "Xs = [X_train_known[i] - X_train_unknown[i] for i in range(len(X_train_known))]\n",
    "print(mean(cross_val_score(DecisionTreeClassifier(), Xs, tr_y, cv=5)))\n",
    "# DecisionTreeClassifier().fit(tr_pairs, y_train)\n",
    "# preds = clf.predict(te_pairs)\n",
    "# accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_known_X = [x.known.vector for x in X_train]\n",
    "train_unknown_X = [x.unknown.vector for x in X_train]\n",
    "test_known_X = [x.known.vector for x in X_test]\n",
    "test_unknown_X = [x.unknown.vector for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(knownX, unknownX):\n",
    "    pairs = []\n",
    "    for i in range(len(knownX)):\n",
    "        pairs += [[knownX[i], unknownX[i]]]\n",
    "    pairs = np.array(pairs)\n",
    "    print(pairs.shape)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 66)\n",
      "(500, 2, 66)\n"
     ]
    }
   ],
   "source": [
    "tr_pairs = create_pairs(knownzs, unknownzs)\n",
    "te_pairs = create_pairs(X_test_known, X_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_y = y_train\n",
    "te_y = y_test\n",
    "\n",
    "shuff_tr_y = tr_y[:]\n",
    "shuff_te_y = te_y[:]\n",
    "from random import shuffle\n",
    "shuffle(shuff_tr_y)\n",
    "shuffle(shuff_te_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truthfile = os.path.join(pan15train, \"truth.txt\")\n",
    "with open(truthfile) as f:\n",
    "    lines = f.read().strip().split(\"\\n\")\n",
    "y = [1 if line.split()[1] == \"Y\" else 0 for line in lines]\n",
    "tr_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_y = y_test\n",
    "tr_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(64, input_shape=(input_dim,), activation='relu'))\n",
    "    seq.add(Dense(64))\n",
    "    seq.add(Dense(64))\n",
    "    seq.add(Dense(64))\n",
    "\n",
    "    return seq\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return np.mean(np.equal(predictions.ravel() < 0.5, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_pairs, te_pairs = te_pairs, tr_pairs\n",
    "tr_y, te_y = te_y, tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_dim = tr_pairs.shape[-1]\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_dim)\n",
    "\n",
    "input_a = Input(shape=(input_dim,))\n",
    "input_b = Input(shape=(input_dim,))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples, validate on 8 samples\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 1s - loss: 6.7165 - val_loss: 4.5169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 0s - loss: 1.8231 - val_loss: 1.9801\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 0s - loss: 0.7780 - val_loss: 0.8940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 0s - loss: 0.3671 - val_loss: 0.5461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 0s - loss: 0.2060 - val_loss: 0.2991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 0s - loss: 0.1372 - val_loss: 0.1982\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 0s - loss: 0.0897 - val_loss: 0.1461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 0s - loss: 0.0664 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 0s - loss: 0.0637 - val_loss: 0.0574\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 0s - loss: 0.0422 - val_loss: 0.0486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 0s - loss: 0.0340 - val_loss: 0.0385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 0s - loss: 0.0307 - val_loss: 0.0409\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 0s - loss: 0.0252 - val_loss: 0.0299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 0s - loss: 0.0217 - val_loss: 0.0313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0274\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 0s - loss: 0.0163 - val_loss: 0.0223\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 0s - loss: 0.0153 - val_loss: 0.0187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0175\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0121\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0209\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e76cef0>"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          validation_split=0.015,\n",
    "          batch_size=20,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 100.00%\n",
      "* Accuracy on test set: 58.00%\n"
     ]
    }
   ],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuff_tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(shuff_tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuff_tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# third-party imports\n",
    "import textacy\n",
    "from spacy.en import English\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def _normalize_counter(counter, c):\n",
    "    \"\"\"Divide all the values in a Counter by a constant and remove padding\"\"\"\n",
    "    for key in counter:\n",
    "        counter[key] = (counter[key] - 1) / c\n",
    "    return counter\n",
    "\n",
    "class TextAnalyser:\n",
    "    def __init__(self, nlp=None):\n",
    "        if nlp:\n",
    "            self.nlp = nlp\n",
    "        else:\n",
    "            self.nlp = English()\n",
    "            \n",
    "        # alphabet for letter ratios\n",
    "        self.alphabet = string.ascii_lowercase + \"!?:;,.'- \"\n",
    "        \n",
    "        # keys that we care about from textacy.stats\n",
    "        self.basic_keys = ['n_long_words', 'n_monosyllable_words', 'n_polysyllable_words', 'n_sents', 'n_syllables', 'n_unique_words', 'n_words']\n",
    "        \n",
    "        # keys that we care about for textacy readability stats\n",
    "        self.readability_keys = ['automated_readability_index','coleman_liau_index', 'flesch_kincaid_grade_level',\n",
    "                                 'flesch_readability_ease', 'gulpease_index', 'gunning_fog_index', 'lix',\n",
    "                                 'wiener_sachtextformel']\n",
    "        \n",
    "        # parts of speech that we care about from spacy (pos_ not tag_)\n",
    "        self.pos_keys = ['ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SPACE', 'SYM', 'VERB', 'X']\n",
    "        self.pos_keys_set = set(self.pos_keys)\n",
    "\n",
    "    def get_named_features(self, text):\n",
    "        # TODO: Add bigrams, trigrams?\n",
    "        processed = self.nlp(text, entity=False, tag=True, parse=True)\n",
    "        stats = textacy.text_stats.TextStats(processed)\n",
    "        basic_stats = stats.basic_counts\n",
    "        readability_stats = stats.readability_stats\n",
    "        cleaned_text = ''.join(filter(lambda x: x in self.alphabet, text.lower() + self.alphabet))\n",
    "        \n",
    "        stats_ratios = {key: (basic_stats[key] / len(text)) for key in self.basic_keys}\n",
    "        readability_ratios = {key: (readability_stats[key] / len(text)) for key in self.readability_keys}\n",
    "        stats_ratios.update(readability_ratios)\n",
    "\n",
    "        # get only the characters we care about \n",
    "        # append alphabet so that each character artificially appears once\n",
    "        char_ratios = Counter(cleaned_text)\n",
    "        char_ratios = _normalize_counter(char_ratios, len(text))\n",
    "\n",
    "        # calculate pos ratios\n",
    "        tags = [word.pos_ for word in processed if word.pos_ in self.pos_keys_set] + self.pos_keys\n",
    "        pos_ratios = Counter(tags)\n",
    "        pos_ratios = _normalize_counter(pos_ratios, len(processed)) # normalize by word length\n",
    "\n",
    "        res = stats_ratios\n",
    "        res.update(char_ratios)\n",
    "        res.update(pos_ratios)\n",
    "        return [(key, res[key]) for key in sorted(res)]\n",
    "    \n",
    "    def calculate_mean_and_std(self, extracted_texts):\n",
    "        \"\"\"finds unusual patterns by calculating mean and std deviation for a list of \n",
    "           extracted features and sorting by z-score\"\"\"\n",
    "        means = []\n",
    "        stds = []\n",
    "        sample = extracted_texts[0]  # get one text for feature size and names\n",
    "        num_features = len(sample)\n",
    "        # fi = feature index\n",
    "        for fi in range(num_features):\n",
    "            u = mean([stat[fi][1] for stat in extracted_texts])\n",
    "            o = stdev([stat[fi][1] for stat in extracted_texts])\n",
    "            means.append((sample[fi][0], u))\n",
    "            stds.append((sample[fi][0], o))\n",
    "        return means, stds\n",
    "    \n",
    "    def calculate_z_scores(self, extracted_text, means, stds):\n",
    "        \"\"\"Calculate the zscores for each features of a single text (extractions)\"\"\"\n",
    "        # z = (X - μ) / σ\n",
    "        zscores = []\n",
    "        num_features = len(extracted_text)\n",
    "        for fi in range(num_features):\n",
    "            feature_name = extracted_text[fi][0]\n",
    "            try:\n",
    "                zscore = (extracted_text[fi][1] - means[fi][1]) / stds[fi][1]\n",
    "            except ZeroDivisionError:\n",
    "                zscore = 0\n",
    "            zscores.append((zscore, feature_name))\n",
    "        return zscores\n",
    "        \n",
    "def vectorize(str_text):\n",
    "    vecs = _vectorize(str_text)\n",
    "    return np.array([x[1] for x in vecs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_unusual_features(zscores, nfeatures=5):\n",
    "    zscores = sorted(zscores)\n",
    "    s = \"\"\n",
    "    for j in range(nfeatures):\n",
    "        fname = zscores[j][1]\n",
    "        padding = \" \" * (30 - len(fname))\n",
    "        s += \"{} is low {}(zscore: {})\\n\".format(fname, padding, zscores[j][0])\n",
    "    s += \"    . . .     \\n\"\n",
    "    for j in range(nfeatures):\n",
    "        fname = zscores[-(j + 1)][1]\n",
    "        padding = \" \" * (30 - len(fname))\n",
    "        s += \"{} is high{}(zscore: {})\\n\".format(fname, padding, zscores[-(j + 1)][0])\n",
    "    return s\n",
    "\n",
    "def supports_and_opposes(zscores1, zscores2, sup_threshold=1.5):\n",
    "    supports = []\n",
    "    opposes = []\n",
    "    for i in range(len(zscores1)):\n",
    "        # both are high or low\n",
    "        if (zscores1[i][0] > sup_threshold and zscores2[i][0] > sup_threshold) or (\n",
    "            zscores1[i][0] < -sup_threshold and zscores2[i][0] < -sup_threshold):\n",
    "            supports.append((zscores1[i], zscores2[i]))\n",
    "        # one is high and the other is low\n",
    "        if (zscores1[i][0] > sup_threshold and zscores2[i][0] < -sup_threshold) or (\n",
    "            zscores1[i][0] < -sup_threshold and zscores2[i][0] > sup_threshold):\n",
    "            opposes.append((zscores1[i], zscores2[i]))\n",
    "    return supports, opposes\n",
    "         \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def t(knowns, unknowns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [1 if p else 0 for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n",
      "WARNING:root:SMOG score may be unreliable for n_sents < 30\n"
     ]
    }
   ],
   "source": [
    "def get(tps):\n",
    "    knownstats = [ta.get_named_features(text) for text in [x.known for x in tps]]\n",
    "    unknownstats = [ta.get_named_features(text) for text in [x.unknown for x in tps]]\n",
    "    means, stds = ta.calculate_mean_and_std(knownstats + unknownstats)\n",
    "    knownzs = [ta.calculate_z_scores(ks, means, stds) for ks in knownstats]\n",
    "    unknownzs = [ta.calculate_z_scores(ks, means, stds) for ks in unknownstats]\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(len(tps)):\n",
    "        z1 = knownzs[i]\n",
    "        z2 = unknownzs[i]\n",
    "        s, o = supports_and_opposes(z1, z2, sup_threshold=0.2)\n",
    "        preds.append(len(s) > len(o))\n",
    "    return preds\n",
    "\n",
    "preds_train = get(X_train)\n",
    "preds_test = get(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 68, False: 32})\n",
      "Counter({True: 288, False: 212})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(preds_train))\n",
    "print(Counter(preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67       250\n",
      "          1       0.67      0.77      0.71       250\n",
      "\n",
      "avg / total       0.70      0.69      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.58      0.71        50\n",
      "          1       0.69      0.94      0.80        50\n",
      "\n",
      "avg / total       0.80      0.76      0.75       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(pan15train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         1\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         1\n",
      "         10       0.00      0.00      0.00         1\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       0.00      0.00      0.00         1\n",
      "         18       0.00      0.00      0.00         1\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.00      0.00      0.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.00      0.00      0.00         1\n",
      "         30       0.00      0.00      0.00         1\n",
      "         31       0.00      0.00      0.00         1\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         1\n",
      "         34       0.00      0.00      0.00         1\n",
      "         35       0.00      0.00      0.00         1\n",
      "         36       0.00      0.00      0.00         1\n",
      "         37       0.00      0.00      0.00         1\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.00      0.00      0.00         1\n",
      "         40       0.00      0.00      0.00         1\n",
      "         41       0.00      0.00      0.00         1\n",
      "         42       0.00      0.00      0.00         1\n",
      "         43       0.00      0.00      0.00         1\n",
      "         44       0.00      0.00      0.00         1\n",
      "         45       0.00      0.00      0.00         1\n",
      "         46       0.00      0.00      0.00         1\n",
      "         47       0.00      0.00      0.00         1\n",
      "         48       0.00      0.00      0.00         1\n",
      "         49       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.00      0.00      0.00        50\n",
      "\n",
      "[11  5 21  8 47 40 25 17 32 39 12  8 15  6 44 28 12 48 30 47 10 47 39 26 35\n",
      "  4 46 15 20  8 18  5  8 43 49  8 39 26 24 20 10 18  9 33  2 11 44 13  2 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "same_X = [x for i, x in enumerate(X_train) if y_train[i]]\n",
    "id_labels = range(0,50)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "classifier = LinearSVC()\n",
    "\n",
    "features = FeatureUnion([\n",
    "    ('char', char_vectorizer),\n",
    "    ('word', word_vectorizer)\n",
    "])\n",
    "\n",
    "features.fit([x.known for x in same_X] + [x.unknown for x in same_X])\n",
    "train_vecs = features.transform([x.known for x in same_X])\n",
    "test_vecs = features.transform([x.unknown for x in same_X])\n",
    "\n",
    "classifier.fit(train_vecs, id_labels)\n",
    "preds = classifier.predict(test_vecs)\n",
    "print(classification_report(id_labels, preds))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_vecs_2 = test_vecs[:10]\n",
    "train_vecs_2 = train_vecs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha=0.001)\n",
    "classifier.fit(train_vecs_2, id_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 8, 0, 9, 7, 7, 3, 5])"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_vecs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"       Hurrah, hurrah, for Santa Claus so dear,\\n           Sure, it was a happy night,\\n           The best one in the year.\\n       And we'll be marching on Christmas.\\n\\n     Nora got a picture-book, Melissa got a rake,\\n     Every Mulligan on deck got oranges and cake,\\n     Got a bag of candy, too--and got the stomachache,\\n       But we'll be marching on Christmas.\\n\\n       Hurrah, hurrah, the Mulligans are here,\\n       Hurrah, hurrah, for Santa Claus so dear,\\n           Sure, it was a happy night,\\n           The best one in the year.\\n       And we'll be marching on Christmas.\\n\\nAnd did ye have a good time at the entertainment?\\n\\nIndade and we did that. It was as good as a circus parade and\\na picture show together. They treated us just lovely.\\n\\nDid they now? And you wasn't invited at all, at all.\\n\\nThey gave us a seat way up in front, and Micky Machree acted\\nlike a pig, he did. Sure, he grabbed two oranges.\\n\\nWhy, Micky, it's ashamed of ye I am.\\n\\nI grabbed one to bring home to you, maw. I wanted you to have\\nsome of the Christmas present, too.\\n\\nThat's just like your father, Micky.\\n\\nAnd did ye have a good time, wee Peter Pan?\\n\\n Scwumptious, just scwumptious.\\n\\nAnd me sash niver busted in two at all. And I was one of the\\nmost stylish young ladies present, so I was.\\n\\nAnd they had a great, big Christmas tree. Clean up to the\\nceiling. With lights and toys and candy and little stars and bright\\nfairies and angels and everything.\\n\\nAnd ould Santy Claus was there with a long white beard and a\\nbig pack of presents to everyone.\\n\\nAnd I pulled Santa Claus' whiskers and they nearly fell off.\\nHe must be getting pretty old, 'cause his whiskers is coming loose.\\n\\n And Santy Claus called out all the names and everybody got up\\nwhen their names was called and he gave 'em a present.\\n\\nAnd they never called our names at all, at all.\\n\\n\\n\""
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_X[3].known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, he's coming, he's\\ncoming. I'm going to get to see Santa Claus! Is it not wonderful? I'm\\ngoing to see him. Let me look.  Oh, it's getting\\nbigger and _bigger_ and BIGGER!\\n\\nHurray! daddy's coming! daddy's coming!\\n\\nNow I can hear the bells. Oh, it's coming closer and _closer_\\nand CLOSER. Look out, it's going to hit the boat! \\n\\nHe flew right by us.\\n\\nMaybe he didn't see the boat. Oh, now he isn't coming at all.\\n\\nYes, he is. He's landed right over there. Here he comes; here he comes!\\n\\nHere we are, Santa Claus. This is the place. Come in. Merry Christmas, Santa Claus, merry Christmas!\\n\\n\\n Hello, there--where are you? It's so dark I can't see a single thing.\\n\\n Hello, daddy; merry Christmas.\\n\\n Hello yourself. Merry Christmas to you, too. Are you all ready for me?\\n\\nYes, it's all ready. The magical tree is just waiting for\\nyour touch to turn into a real Christmas tree.\\n\\n Oh, we're going to have a real Christmas tree.\\n\\nHello, who's this young person?\\n\\nThis is Anita.\\n\\nAnd why isn't she sound asleep like the rest of the\\nchildren?\\n\\nShe's such a good little girl that I told her she could\\nstay up with me and wait until you came.\\n\\nOh, ho; so you've made a hit with my boy, Jack\\nFrost, have you? Well, if that's the case, I guess you can stay.\\n\\nBut all of the children would like to see you, Santa Claus.\\nSee, they've prepared the candle and the wreath of holly and the star\\nof Bethlehem all for you. There's Sergius and Tomasso and Hulda and\\nMeeny and Hans and Yakob and Neelda and Ah Goo and Sano San and Mieze\\nand the leetla Dutch twins, Klinker and Schwillie Willie Winkum.\\nThey've all been awfully good children. And Biddy Mary and Paddy Mike\\nthey brought the candle. They're good, too.\\n\\n\\n\""
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_X[0].unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
