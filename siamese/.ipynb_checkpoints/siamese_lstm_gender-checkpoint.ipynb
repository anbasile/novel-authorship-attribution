{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/g/git/pan17/src_gronup/\")\n",
    "from pipeline import *\n",
    "\n",
    "emojis = [e for e in emoji.UNICODE_EMOJI]\n",
    "\n",
    "\n",
    "feats = FeatureUnion([\n",
    "               ('EmoticonNoses', features.EmoticonNoses()),\n",
    "               # ('EmoticonReverse', features.EmoticonReverse()),\n",
    "               # ('EmoticonCount', features.EmoticonCount()),\n",
    "               # ('EmoticonEmotion', features.EmoticonEmotion()),\n",
    "               # ('StartsWithCapital', features.StartsWithCapital()),\n",
    "               # ('EndsWithPunctuation', features.EndsWithPunctuation()),\n",
    "               # ('AverageWordLength', features.AverageWordLength()),\n",
    "               # ('AverageSentenceLength', features.AverageSentenceLength()),\n",
    "               # ('PunctuationByTweet', features.PunctuationByTweet()),\n",
    "               # ('CapitalizedTokens', features.CapitalizedTokens()),\n",
    "               # ('CapitalLetters', features.CapitalLetters()),\n",
    "               ('VocabularyRichness', features.VocabularyRichness()),\n",
    "               ('wordvec', TfidfVectorizer(ngram_range = (1,3), preprocessor = lambda x: x, tokenizer = identity)),\n",
    "               ('charvec', TfidfVectorizer(analyzer = 'char', ngram_range = (2,5), preprocessor = lambda x: ' '.join(identity(x)))),\n",
    "               ('emojivec', TfidfVectorizer(analyzer = 'char', preprocessor = lambda x: ' '.join(identity(x)), vocabulary=emojis)),\n",
    "               ('FunctionWords', features.FunctionWords(2500))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for preprocessing raw text before feeding it into a Neural Net\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# Map printable characters to ints and vice-versa\n",
    "ALPHABET = string.printable\n",
    "\n",
    "char2int = dict((c, i) for i, c in enumerate(ALPHABET))\n",
    "int2char = dict((i, c) for i, c in enumerate(ALPHABET))\n",
    "\n",
    "\n",
    "def c2i(char):\n",
    "    return char2int[char]\n",
    "\n",
    "def i2c(num):\n",
    "    return int2char[num]\n",
    "\n",
    "\n",
    "def vectorize_text(text):\n",
    "    \"\"\"Convert a text into integers\"\"\"\n",
    "    X = []\n",
    "    text = ''.join(list(filter(lambda x: x in ALPHABET, text)))\n",
    "    X = [c2i(char) for char in text]\n",
    "    X = np.array(X)\n",
    "    X = X / float(len(ALPHABET))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(vectorize_text([ALPHABET]).shape)\n",
    "# print(len(ALPHABET))\n",
    "# print(ALPHABET[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_pan17\n",
    "\n",
    "gender_data = load_pan17(\"/data/pan17/pan17-author-profiling-training-dataset-2017-03-10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "males = gender_data.corpus[(gender_data.corpus[\"gender\"]==\"male\") & (gender_data.corpus[\"lang\"]==\"en\")]\n",
    "females = gender_data.corpus[(gender_data.corpus[\"gender\"]==\"female\") & (gender_data.corpus[\"lang\"]==\"en\")]\n",
    "\n",
    "mtexts = [\" \" .join(males.iloc[i].text) for i in range(len(males))]\n",
    "ftexts = [\" \" .join(females.iloc[i].text) for i in range(len(females))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tk = Tokenizer(num_words=100000)\n",
    "tk.fit_on_texts(mtexts + ftexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mX = tk.texts_to_sequences(mtexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fX = tk.texts_to_sequences(ftexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_review_length = 5000\n",
    "mX = sequence.pad_sequences(mX, maxlen=max_review_length)\n",
    "fX = sequence.pad_sequences(fX, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "labels = []\n",
    "i = 0\n",
    "while i < len(mX):\n",
    "    pairs.append([mX[i], mX[i+1]])\n",
    "    pairs.append([fX[i], fX[i+1]])\n",
    "    pairs.append([mX[i], fX[i]])\n",
    "    pairs.append([mX[i+1], fX[i+1]])\n",
    "    i += 2\n",
    "labels = [1,1,0,0] * (int(len(mX)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pairs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    9   132  2151    15   151    56    35    24   219     4   189    19\n",
      "    16    44     8  1008 42712 21060 25282    22   453  4943   535     5\n",
      "  2615    17    53    96  1855    39   263  2299   610   331   102 31659\n",
      "   134  3778  2954  8072     9  4066   302     4   369     9     4    85\n",
      "   538   112     5     4  1140   521     7   134  1872    18  2050  3684\n",
      "   286  5455    50    13    96    20   237     6  7238    67    32   112\n",
      "     4   144   359     4   805   868    14  7202   107   150 17183    46\n",
      "   240    88     5 32392    15    57   569   108     4   189   224    17\n",
      "    12     4   948   102]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[500][0][-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats.fit(ftexts + mtexts, [0] * len(ftexts) + [1] * len(mtexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mX = feats.transform(mtexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fX = feats.transform(ftexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mX = mX.todense()\n",
    "fX = fX.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 378307)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fX2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "labels = []\n",
    "i = 0\n",
    "while i < mX.shape[0]:\n",
    "    pairs.append([mX[i], mX[i+1]])\n",
    "    pairs.append([fX[i], fX[i+1]])\n",
    "    pairs.append([mX[i], fX[i]])\n",
    "    pairs.append([mX[i+1], fX[i+1]])\n",
    "    i += 2\n",
    "labels = [1,1,0,0] * (int(mX.shape[0]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_pairs, te_pairs, tr_y, te_y = train_test_split(pairs, labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Embedding, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    embedding_vecor_length = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(100000, embedding_vecor_length, input_length=5000))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def create_base_network_old(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(128, input_shape=(input_dim,), activation='relu'))\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    # seq.add(Dropout(0.1))\n",
    "    # seq.add(Dense(512, activation='relu'))\n",
    "    # seq.add(Dense(512, activation='relu'))\n",
    "    # seq.add(Dense(512, activation='relu'))\n",
    "    # seq.add(Dropout(0.1))\n",
    "    # seq.add(Dense(512, activation='relu'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return np.mean(np.equal(predictions.ravel() < 0.5, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_pairs = np.array(X_train)\n",
    "te_pairs = np.array(X_test)\n",
    "tr_y = np.array(y_train)\n",
    "te_y = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2, 5000)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_pairs_s = tr_pairs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3600 into shape (3600,2,378307)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7afa239055cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_pairs_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3600 into shape (3600,2,378307)"
     ]
    }
   ],
   "source": [
    "tr_pairs_s.reshape(3600, 2, mX.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_pairs = tr_pairs.reshape(1800, 2, mX.shape[1])\n",
    "te_pairs = te_pairs.reshape(mX.shape[0], 2, mX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-9d2f5e260ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_dim = tr_pairs.shape[-1]\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_dim)\n",
    "\n",
    "input_a = Input(shape=(input_dim,))\n",
    "input_b = Input(shape=(input_dim,))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(input=[input_a, input_b], output=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 269 samples, validate on 2431 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "'''tr_pairs1 = tr_pairs[:250]\n",
    "te_pairs1 = tr_pairs[250:]\n",
    "tr_y1 = tr_y[:250]\n",
    "te_y1 = tr_y[250:]\n",
    "\n",
    "tr_pairs = tr_pairs1\n",
    "te_pairs = te_pairs1\n",
    "tr_y = tr_y1\n",
    "te_y = te_y1\n",
    "'''\n",
    "# tr_pairs = np.vstack([tr_pairs, te_pairs])\n",
    "# print(tr_pairs.shape)\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer='adam', metrics=['acc'])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          validation_split=0.9,\n",
    "          batch_size=240,\n",
    "          epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 50.17%\n",
      "* Accuracy on test set: 49.83%\n"
     ]
    }
   ],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(te_y, [1 if x < 0.5 else 0 for x in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2, 1200)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([tr_pairs, te_pairs]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2, 1200)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1200)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pairs[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([tr_y,te_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
