\chapter{Conclusion}

In this chapter, we provide a brief summary and discussion of our methods and results, suggesting areas for future work where applicable.

We presented several methods for identifying authors by their writing style alone. Although our results were in many cases lower than we hoped, we believe that all three broad techniques that we presented (namely, unsupervised statistical approaches; approaches using Support Vector Machines; and approaches using Neural Networks) provide value in different ways. We discuss each of these below.

Our Unsupervised approach used descriptive statistics to compare texts of interest to larger corpora. If two texts differ from the corpus in the same, this provides evidence that both texts are written by the same author. This method is interesting in that it is not a ``black box'', unlike the other methods. This means that it can provide expert humans with interpretable data, and can be used in combination with manual analysis or with the other methods to provide evidence about who the author of a disputed work is. This is the method that is easiest to understand, and can therefore be used to provide evidence and arguments to non-experts, for example, in a court of law. Although the results we achieved with this method were not brilliant, we believe that the ease of interpretation is important in many cases. More research is needed to find features and data that lead to better and more consistent results. Further, this technique relies on many language-specific tools, and would face large limitations if used for smaller languages for which such tools are often not available.

Our Support Vector Machine approaches are valuable for their simplicity and scalability. They were able to quickly process large amounts of data, making them practical for large datasets that would take far too long to process using our neural network methods, or many methods presented by other researchers that could achieve state-of-the-art results on smaller datasets. These models also showed flexibility, and were able to work across datasets, languages, and tasks. More research is needed to find out how to select the right training data to make these models perform well in practical situations where the the test data is unique.

The Neural Network methods we presented arguably have the most potential. With so many variations in model architecture and hyperparameters to explore, they are also the most difficult to get right. We expect many advances in the near future in using Neural Networks for NLP tasks, and we expect that some of these advances will be useful to finding a Neural Network configuration that is able to accurately model writing style. More work is needed to experiment with the almost countless ways to solve Authorship Attribution tasks.
\label{chap:con}
